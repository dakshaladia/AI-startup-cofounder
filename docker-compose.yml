version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: startup_cofounder
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d startup_cofounder"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for task queue
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Backend FastAPI service
  backend:
    build:
      context: ./services/backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:password@postgres:5432/startup_cofounder
      - REDIS_URL=redis://redis:6379/0
      - VECTOR_DB_TYPE=faiss
      - VECTOR_DB_PATH=/app/data/faiss_index
      - CORS_ORIGINS=["http://localhost:3000","http://localhost:8501"]
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - LLM_PROVIDER=gemini
      - LLM_MODEL=gemini-2.0-flash-lite
      - TEXT_EMBEDDING_MODEL=text-embedding-004
      - TEXT_EMBEDDING_DIMENSION=768
    volumes:
      - ./data:/app/data
      - ./services/backend:/app
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  # Ingestion worker
  ingestion-worker:
    build:
      context: ./services/ingestion
      dockerfile: Dockerfile
    environment:
      - DATABASE_URL=postgresql://user:password@postgres:5432/startup_cofounder
      - REDIS_URL=redis://redis:6379/0
      - VECTOR_DB_TYPE=faiss
      - VECTOR_DB_PATH=/app/data/faiss_index
    volumes:
      - ./data:/app/data
      - ./services/ingestion:/app
    depends_on:
      - postgres
      - redis
    command: python -m workers.ingest_worker

  # Next.js Frontend
  frontend:
    build:
      context: ./frontend/web
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8000
    volumes:
      - ./frontend/web:/app
      - /app/node_modules
    depends_on:
      - backend
    command: npm run dev

  # Streamlit Demo
  demo:
    build:
      context: ./frontend/demo
      dockerfile: Dockerfile
    ports:
      - "8501:8501"
    environment:
      - API_URL=http://backend:8000
    volumes:
      - ./frontend/demo:/app
    depends_on:
      - backend
    command: streamlit run app.py --server.port 8501 --server.address 0.0.0.0

  # Optional: Weaviate vector database
  weaviate:
    image: semitechnologies/weaviate:latest
    ports:
      - "8080:8080"
    environment:
      - QUERY_DEFAULTS_LIMIT=25
      - AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true
      - PERSISTENCE_DATA_PATH=/var/lib/weaviate
      - DEFAULT_VECTORIZER_MODULE=none
      - ENABLE_MODULES=text2vec-openai,text2vec-cohere,text2vec-huggingface,img2vec-neural,text2vec-contextionary,text2vec-transformers
      - CLUSTER_HOSTNAME=node1
    volumes:
      - weaviate_data:/var/lib/weaviate
    profiles:
      - production

volumes:
  postgres_data:
  redis_data:
  weaviate_data:
